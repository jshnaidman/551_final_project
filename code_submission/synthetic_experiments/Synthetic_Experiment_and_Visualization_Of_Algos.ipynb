{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from collections import defaultdict\n",
    "from itertools import zip_longest\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_t(x):\n",
    "    c = np.random.choice([1010,-10], p=[0.01,0.99])\n",
    "    return x*float(c)\n",
    "\n",
    "def f_t_mod(x,t):\n",
    "    if(t%101 == 1):\n",
    "        c=1010\n",
    "    else:\n",
    "        c=(-10)\n",
    "    return x*float(c)\n",
    "\n",
    "# Beale's function\n",
    "f  = lambda x, y: (1.5 - x + x*y)**2 + (2.25 - x + x*y**2)**2 + (2.625 - x + x*y**3)**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regret(loss_sum,min_loss_sum,t):\n",
    "    return (loss_sum - min_loss_sum)/t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer,lr,t):\n",
    "    new_lr = lr/np.sqrt(t)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from amsgrad import Amsgrad\n",
    "\n",
    "iters = int(8e6)\n",
    "# iters = int(1e4)\n",
    "\n",
    "my_lr = 1\n",
    "beta = (0.9,0.99)\n",
    "\n",
    "t=1\n",
    "\n",
    "total_loss_amsgrad = 0\n",
    "total_min_loss_amsgrad = 0\n",
    "\n",
    "total_loss_adam = 0\n",
    "total_min_loss_adam = 0\n",
    "\n",
    "x_var_adam = 0\n",
    "x_var_amsgrad = 0\n",
    "\n",
    "# n = np.random.rand(1,1)\n",
    "n = 0\n",
    "\n",
    "# Create a tensor with one value (x_t) and initialize the optimizers\n",
    "x_var_adam = Variable(torch.FloatTensor([n]), requires_grad=True)\n",
    "adam = torch.optim.Adam([x_var_adam], betas=beta, lr=my_lr)\n",
    "\n",
    "x_var_amsgrad = Variable(torch.FloatTensor([n]), requires_grad=True)\n",
    "amsgrad = Amsgrad([x_var_amsgrad], betas=beta , lr=my_lr)\n",
    "\n",
    "print(x_var_amsgrad.data[0])\n",
    "print(x_var_adam.data[0])\n",
    "\n",
    "\n",
    "x_var_adam_hist = [x_var_adam.data[0]]\n",
    "x_var_amsgrad_hist = [x_var_amsgrad.data[0]]\n",
    "\n",
    "\n",
    "regret_adam_hist=[]\n",
    "regret_amsgrad_hist=[]\n",
    "\n",
    "\n",
    "# Closure to be ran during optimizer step\n",
    "def closure_adam(): \n",
    "    c = 1010 if t%101 == 1 else -10\n",
    "    \n",
    "    adam.zero_grad()\n",
    "    loss = f_t_mod(x_var_adam,t)\n",
    "    loss.backward()\n",
    "    \n",
    "    global total_loss_adam\n",
    "    total_loss_adam += loss.data[0]\n",
    "    \n",
    "    global total_min_loss_adam\n",
    "    \n",
    "    #minimum point is at -1\n",
    "    total_min_loss_adam += -1*c\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Closure to be ran during optimizer step\n",
    "def closure_amsgrad(): \n",
    "    \n",
    "    c = 1010 if t%101 == 1 else -10\n",
    "    \n",
    "    amsgrad.zero_grad()\n",
    "    loss = f_t_mod(x_var_amsgrad,t)\n",
    "    loss.backward()\n",
    "    \n",
    "    global total_loss_amsgrad\n",
    "    total_loss_amsgrad += loss.data[0]\n",
    "    \n",
    "    global total_min_loss_amsgrad\n",
    "    \n",
    "    #minimum point is at -1\n",
    "    total_min_loss_amsgrad += -1*c\n",
    "    \n",
    "    return loss\n",
    "\n",
    "t=1\n",
    "for i in range(iters):\n",
    "    \n",
    "    #zero the gradients\n",
    "    amsgrad.zero_grad()\n",
    "    adam.zero_grad()\n",
    "    \n",
    "    #Perform an optimization step\n",
    "    adam.step(closure_adam)\n",
    "    amsgrad.step(closure_amsgrad)\n",
    "    \n",
    "    #Clamp the variables between -1 and 1\n",
    "    x_var_adam.data = x_var_adam.data.clamp(-1,1)\n",
    "    x_var_amsgrad.data = x_var_amsgrad.data.clamp(-1,1)\n",
    "    \n",
    "    #Calculate the regret\n",
    "    adam_regret = regret(total_loss_adam,total_min_loss_adam,t)\n",
    "    ams_regret = regret(total_loss_amsgrad,total_min_loss_amsgrad,t)\n",
    "    \n",
    "    #Store regret\n",
    "    regret_adam_hist.append(adam_regret)\n",
    "    regret_amsgrad_hist.append(ams_regret)\n",
    "\n",
    "    #Store the x_t values\n",
    "    x_var_adam_hist.append(x_var_adam.data[0])\n",
    "    x_var_amsgrad_hist.append(x_var_amsgrad.data[0])\n",
    "    \n",
    "    #Adjust learning rate by dividing by sqrt(t)\n",
    "    adjust_learning_rate(adam,my_lr,t)\n",
    "    adjust_learning_rate(amsgrad,my_lr,t)\n",
    "    t+=1\n",
    "    \n",
    "\n",
    "\n",
    "# regret_adam = np.ndarray(x,regret_adam_hist)\n",
    "# regret_amsgrad = np.ndarray(x,regret_amsgrad_hist)\n",
    "\n",
    "\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = int(1e7)\n",
    "# iters=int(1e5)\n",
    "\n",
    "my_lr = 5e-4 # 1e-4 was very good - slightly slow\n",
    "\n",
    "\n",
    "t=1\n",
    "\n",
    "\n",
    "#Initialize \n",
    "x_var_adam = Variable(torch.FloatTensor([0]), requires_grad=True)\n",
    "adam = torch.optim.Adam([x_var_adam], betas=beta, lr=my_lr)\n",
    "\n",
    "x_var_amsgrad = Variable(torch.FloatTensor([0]), requires_grad=True)\n",
    "amsgrad = Amsgrad([x_var_amsgrad], lr=my_lr, betas=beta)\n",
    "\n",
    "x_var_adam_hist = [x_var_adam.data[0]]\n",
    "x_var_amsgrad_hist = [x_var_amsgrad.data[0]]\n",
    "\n",
    "# Closure to be ran during optimizer step\n",
    "def closure_adam(): \n",
    "    c = 1010 if t%101 == 1 else -10\n",
    "    \n",
    "    adam.zero_grad()\n",
    "    loss = f_t(x_var_adam)\n",
    "    loss.backward()\n",
    "    \n",
    "    global total_loss_adam\n",
    "    total_loss_adam += loss.data[0]\n",
    "    \n",
    "    global total_min_loss_adam\n",
    "    \n",
    "    #minimum point is at -1\n",
    "    total_min_loss_adam += -1*c\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Closure to be ran during optimizer step\n",
    "def closure_amsgrad(): \n",
    "    \n",
    "    c = 1010 if t%101 == 1 else -10\n",
    "    \n",
    "    amsgrad.zero_grad()\n",
    "    loss = f_t(x_var_amsgrad)\n",
    "    loss.backward()\n",
    "    \n",
    "    global total_loss_amsgrad\n",
    "    total_loss_amsgrad += loss.data[0]\n",
    "    \n",
    "    global total_min_loss_amsgrad\n",
    "    \n",
    "    #minimum point is at -1\n",
    "    total_min_loss_amsgrad += -1*c\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "t=1\n",
    "for i in range(iters):\n",
    "    amsgrad.zero_grad()\n",
    "    adam.zero_grad()\n",
    "    \n",
    "    adam.step(closure_adam)\n",
    "    amsgrad.step(closure_amsgrad)\n",
    "    \n",
    "    x_var_adam.data = x_var_adam.data.clamp(-1,1)\n",
    "    x_var_amsgrad.data = x_var_amsgrad.data.clamp(-1,1)\n",
    "    \n",
    "    x_var_adam_hist.append(x_var_adam.data[0])\n",
    "    x_var_amsgrad_hist.append(x_var_amsgrad.data[0])\n",
    "    \n",
    "    #Adjust learning rate by dividing by sqrt(t)\n",
    "#     adjust_learning_rate(adam,my_lr,t)\n",
    "#     adjust_learning_rate(amsgrad,my_lr,t)\n",
    "    \n",
    "    t+=1\n",
    "t=1\n",
    "    \n",
    "    \n",
    "xsteps = [0, 3e6, 6e6, 9e6]\n",
    "fig1, ax1 = plt.subplots()\n",
    "x = list(range(0,iters+1))\n",
    "plt.plot(x, x_var_adam_hist, label=\"adam\", c='b', ls='--')\n",
    "plt.plot(x, x_var_amsgrad_hist, label=\"amsgrad\", c='g')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"$x_t$\")\n",
    "ax1.xaxis.set_major_formatter(mtick.FormatStrFormatter('%.2e'))\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "plt.axis([0, iters, -1, 1])\n",
    "ax1.grid(color='gray', linewidth=1)\n",
    "ax1.legend(loc='best')\n",
    "ax1.set_xticks(xsteps)\n",
    "plt.show()\n",
    "    \n",
    "\n",
    "print(x_var_amsgrad.data[0])\n",
    "print(x_var_adam.data[0])\n",
    "\n",
    "\n",
    "import os\n",
    "os.system('spd-say \"your program has finished\"')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsteps = [0, 3e6, 6e6, 9e6]\n",
    "fig1, ax1 = plt.subplots()\n",
    "x = list(range(0,iters+1))\n",
    "plt.plot(x, x_var_adam_hist, label=\"adam\", c='b', ls='--')\n",
    "plt.plot(x, x_var_amsgrad_hist, label=\"amsgrad\", c='g')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"$x_t$\")\n",
    "ax1.xaxis.set_major_formatter(mtick.FormatStrFormatter('%.2e'))\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "plt.axis([0, iters, -1, 1])\n",
    "ax1.grid(color='gray', linewidth=1)\n",
    "ax1.legend(loc='best')\n",
    "plt.rc('xtick', labelsize=40)\n",
    "plt.rc('ytick', labelsize=40)\n",
    "ax1.set_xticks(xsteps)\n",
    "plt.show()\n",
    "    \n",
    "\n",
    "print(x_var_amsgrad.data[0])\n",
    "print(x_var_adam.data[0])\n",
    "\n",
    "\n",
    "import os\n",
    "os.system('spd-say \"your program has finished\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything Below here was just for visualizing the algorithms for the presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beale's function\n",
    "f  = lambda x, y: (1.5 - x + x*y)**2 + (2.25 - x + x*y**2)**2 + (2.625 - x + x*y**3)**2\n",
    "\n",
    "xmin, xmax, xstep = -4.5, 4.5, .2\n",
    "ymin, ymax, ystep = -4.5, 4.5, .2\n",
    "\n",
    "x, y = np.meshgrid(np.arange(xmin, xmax + xstep, xstep), np.arange(ymin, ymax + ystep, ystep))\n",
    "\n",
    "def getMinima(x,y):\n",
    "    minima = np.array([float(x),float(y)])\n",
    "    minima = minima.reshape(-1,1)\n",
    "    return minima\n",
    "\n",
    "\n",
    "x, y = np.meshgrid(np.arange(xmin, xmax + xstep, xstep), np.arange(ymin, ymax + ystep, ystep))\n",
    "z = f(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minima = getMinima(3,0.5)\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = plt.axes(projection='3d', elev=50, azim=-50)\n",
    "\n",
    "ax.plot_surface(x, y, z, norm=LogNorm(), rstride=1, cstride=1, \n",
    "                edgecolor='none', alpha=.8, cmap=plt.cm.jet)\n",
    "ax.plot(*minima, f(*minima), 'r*', markersize=10)\n",
    "\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "ax.set_zlabel('$z$')\n",
    "\n",
    "ax.set_xlim((xmin, xmax))\n",
    "ax.set_ylim((ymin, ymax))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([3., 4.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_adam = Variable(torch.FloatTensor(x0), requires_grad=True)\n",
    "adam = torch.optim.Adam([w_adam], lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_ft(x,y):\n",
    "    c = np.random.choice([1010,-10], p=[0.01,0.99])\n",
    "    c = np.array([float(c)])\n",
    "    c = Variable(torch.FloatTensor(c))\n",
    "    return (c*x + c*y)\n",
    "\n",
    "def beales_var(var):\n",
    "    x = var[0]\n",
    "    y = var[1]\n",
    "    \n",
    "    return ((1.5 - x + x*y).pow(2) + (2.25 - x + (x*y).pow(2)).pow(2) + (2.625 - x + (x*y).pow(3)).pow(2))\n",
    "#     return var_ft(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameterized_closure(optimizer,f,w):\n",
    "    def closure(): \n",
    "        optimizer.zero_grad()\n",
    "        loss = f(w)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    return closure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(optim, f, w, steps, length):\n",
    "    closure = get_parameterized_closure(optim,f,w)\n",
    "    path = np.ndarray(shape=(steps,2),dtype=float)\n",
    "    for step in range(steps):\n",
    "        optim.step(closure)\n",
    "        path[step][0] = w[0].data[0]\n",
    "        path[step][1] = w[1].data[0]\n",
    "    result = np.ndarray(shape=(length,2),dtype=float)\n",
    "    idx = 0\n",
    "    for n in np.linspace(0,steps-1,num=length, dtype=int):\n",
    "        result[idx] = path[n]\n",
    "        idx += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = optimize(adam,beales_var,w_adam,10000, 100).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.contour(x, y, z, levels=np.logspace(0, 5, 35), norm=LogNorm(), cmap=plt.cm.jet)\n",
    "ax.quiver(path[0,:-1], path[1,:-1], path[0,1:]-path[0,:-1], path[1,1:]-path[1,:-1], scale_units='xy', angles='xy', scale=1, color='k')\n",
    "ax.plot(*minima, 'r*', markersize=18)\n",
    "\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "\n",
    "ax.set_xlim((xmin, xmax))\n",
    "ax.set_ylim((ymin, ymax))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.contour(x, y, z, levels=np.logspace(0, 5, 35), norm=LogNorm(), cmap=plt.cm.jet)\n",
    "ax.plot(*minima, 'r*', markersize=18)\n",
    "\n",
    "line, = ax.plot([], [], 'b', label='amsgrad', lw=2)\n",
    "point, = ax.plot([], [], 'bo')\n",
    "\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "\n",
    "ax.set_xlim((xmin, xmax))\n",
    "ax.set_ylim((ymin, ymax))\n",
    "\n",
    "ax.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    line.set_data([], [])\n",
    "    point.set_data([], [])\n",
    "    return line, point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate(i):\n",
    "    line.set_data(*path[::,:i])\n",
    "    point.set_data(*path[::,i-1:i])\n",
    "    return line, point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=path.shape[1], interval=60, \n",
    "                               repeat_delay=5, blit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_3d = plt.figure(figsize=(8, 5))\n",
    "ax = plt.axes(projection='3d', elev=50, azim=-50)\n",
    "\n",
    "ax.plot_surface(x, y, z, norm=LogNorm(), rstride=1, cstride=1, edgecolor='none', alpha=.8, cmap=plt.cm.jet)\n",
    "ax.plot(*minima, f(*minima), 'r*', markersize=10)\n",
    "\n",
    "line_3d, = ax.plot([], [], [], 'b', label='Newton-CG', lw=2)\n",
    "point_3d, = ax.plot([], [], [], 'bo')\n",
    "\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "ax.set_zlabel('$z$')\n",
    "\n",
    "ax.set_xlim((xmin, xmax))\n",
    "ax.set_ylim((ymin, ymax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_3d():\n",
    "    line_3d.set_data([], [])\n",
    "    line_3d.set_3d_properties([])\n",
    "    point_3d.set_data([], [])\n",
    "    point_3d.set_3d_properties([])\n",
    "    return line, point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate_3d(i):\n",
    "    line_3d.set_data(path[0,:i], path[1,:i])\n",
    "    line_3d.set_3d_properties(f(*path[::,:i]))\n",
    "    point_3d.set_data(path[0,i-1:i], path[1,i-1:i])\n",
    "    point_3d.set_3d_properties(f(*path[::,i-1:i]))\n",
    "    return line, point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = animation.FuncAnimation(fig_3d, animate_3d, init_func=init_3d,\n",
    "                               frames=path.shape[1], interval=60, \n",
    "                               repeat_delay=5, blit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryAnimation(animation.FuncAnimation):\n",
    "    \n",
    "    def __init__(self, *paths, labels=[], fig=None, ax=None, frames=None, \n",
    "                 interval=60, repeat_delay=5, blit=True, **kwargs):\n",
    "\n",
    "        if fig is None:\n",
    "            if ax is None:\n",
    "                fig, ax = plt.subplots()\n",
    "            else:\n",
    "                fig = ax.get_figure()\n",
    "        else:\n",
    "            if ax is None:\n",
    "                ax = fig.gca()\n",
    "\n",
    "        self.fig = fig\n",
    "        self.ax = ax\n",
    "        \n",
    "        self.paths = paths\n",
    "\n",
    "        if frames is None:\n",
    "            frames = max(path.shape[1] for path in paths)\n",
    "  \n",
    "        self.lines = [ax.plot([], [], label=label, lw=2)[0] \n",
    "                      for _, label in zip_longest(paths, labels)]\n",
    "        self.points = [ax.plot([], [], 'o', color=line.get_color())[0] \n",
    "                       for line in self.lines]\n",
    "\n",
    "        super(TrajectoryAnimation, self).__init__(fig, self.animate, init_func=self.init_anim,\n",
    "                                                  frames=frames, interval=interval, blit=blit,\n",
    "                                                  repeat_delay=repeat_delay, **kwargs)\n",
    "\n",
    "    def init_anim(self):\n",
    "        for line, point in zip(self.lines, self.points):\n",
    "            line.set_data([], [])\n",
    "            point.set_data([], [])\n",
    "        return self.lines + self.points\n",
    "\n",
    "    def animate(self, i):\n",
    "        for line, point, path in zip(self.lines, self.points, self.paths):\n",
    "            line.set_data(*path[::,:i])\n",
    "            point.set_data(*path[::,i-1:i])\n",
    "        return self.lines + self.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryAnimation3D(animation.FuncAnimation):\n",
    "    \n",
    "    def __init__(self, *paths, zpaths, labels=[], fig=None, ax=None, frames=None, \n",
    "                 interval=60, repeat_delay=5, blit=True, **kwargs):\n",
    "\n",
    "        if fig is None:\n",
    "            if ax is None:\n",
    "                fig, ax = plt.subplots()\n",
    "            else:\n",
    "                fig = ax.get_figure()\n",
    "        else:\n",
    "            if ax is None:\n",
    "                ax = fig.gca()\n",
    "\n",
    "        self.fig = fig\n",
    "        self.ax = ax\n",
    "        \n",
    "        self.paths = paths\n",
    "        self.zpaths = zpaths\n",
    "        \n",
    "        if frames is None:\n",
    "            frames = max(path.shape[1] for path in paths)\n",
    "  \n",
    "        self.lines = [ax.plot([], [], [], label=label, lw=2)[0] \n",
    "                      for _, label in zip_longest(paths, labels)]\n",
    "\n",
    "        super(TrajectoryAnimation3D, self).__init__(fig, self.animate, init_func=self.init_anim,\n",
    "                                                  frames=frames, interval=interval, blit=blit,\n",
    "                                                  repeat_delay=repeat_delay, **kwargs)\n",
    "\n",
    "    def init_anim(self):\n",
    "        for line in self.lines:\n",
    "            line.set_data([], [])\n",
    "            line.set_3d_properties([])\n",
    "        return self.lines\n",
    "\n",
    "    def animate(self, i):\n",
    "        for line, path, zpath in zip(self.lines, self.paths, self.zpaths):\n",
    "            line.set_data(*path[::,:i])\n",
    "            line.set_3d_properties(zpath[:i])\n",
    "        return self.lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beale's function\n",
    "f  = lambda x, y: (1.5 - x + x*y)**2 + (2.25 - x + x*y**2)**2 + (2.625 - x + x*y**3)**2\n",
    "\n",
    "xmin, xmax, xstep = -4.5, 4.5, .2\n",
    "ymin, ymax, ystep = -4.5, 4.5, .2\n",
    "\n",
    "x, y = np.meshgrid(np.arange(xmin, xmax + xstep, xstep), np.arange(ymin, ymax + ystep, ystep))\n",
    "\n",
    "def getMinima(x,y):\n",
    "    minima = np.array([float(x),float(y)])\n",
    "    minima = minima.reshape(-1,1)\n",
    "    return minima\n",
    "\n",
    "\n",
    "x, y = np.meshgrid(np.arange(xmin, xmax + xstep, xstep), np.arange(ymin, ymax + ystep, ystep))\n",
    "z = f(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amsgrad import Amsgrad\n",
    "\n",
    "x0 = np.array([-3., 4.])\n",
    "\n",
    "\n",
    "algos = {}\n",
    "\n",
    "\n",
    "w_adadelta = Variable(torch.FloatTensor(x0), requires_grad=True)\n",
    "adadelta = torch.optim.Adadelta([w_adadelta])\n",
    "algos['adadelta'] = [adadelta,beales_var,w_adadelta]\n",
    "\n",
    "w_amsgrad = Variable(torch.FloatTensor(x0), requires_grad=True)\n",
    "amsgrad = Amsgrad([w_amsgrad])\n",
    "algos['amsgrad'] = [amsgrad,beales_var,w_amsgrad]\n",
    "\n",
    "w_adagrad = Variable(torch.FloatTensor(x0), requires_grad=True)\n",
    "adagrad = torch.optim.Adagrad([w_adagrad], lr=1)\n",
    "algos['adagrad'] = [adagrad,beales_var,w_adagrad]\n",
    "\n",
    "w_rmsprop = Variable(torch.FloatTensor(x0), requires_grad=True)\n",
    "rmsprop = torch.optim.RMSprop([w_rmsprop])\n",
    "algos['rmsprop'] = [rmsprop,beales_var,w_rmsprop]\n",
    "\n",
    "\n",
    "sgd_lr = 1e-9\n",
    "\n",
    "w_sgd = Variable(torch.FloatTensor(x0), requires_grad=True)\n",
    "sgd = torch.optim.SGD([w_sgd], lr=sgd_lr)\n",
    "algos['sgd'] = [sgd,beales_var,w_sgd]\n",
    "\n",
    "w_sgdm = Variable(torch.FloatTensor(x0), requires_grad=True)\n",
    "sgdm = torch.optim.SGD([w_sgdm], lr=1e-11, momentum=0.9)\n",
    "algos['sgd_momentum'] = [sgdm,beales_var,w_sgdm]\n",
    "\n",
    "w_nesterov = Variable(torch.FloatTensor(x0), requires_grad=True)\n",
    "nesterov = torch.optim.SGD([w_nesterov], lr=sgd_lr, momentum=0.9, nesterov=True)\n",
    "algos['sgd_nesterov'] = [nesterov,beales_var,w_nesterov]\n",
    "\n",
    "\n",
    "w_adam = Variable(torch.FloatTensor(x0), requires_grad=True)\n",
    "adam = torch.optim.Adam([w_adam], lr=0.01)\n",
    "algos['adam'] = [adam,beales_var,w_adam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "methods = []\n",
    "zpaths = []\n",
    "\n",
    "for key in algos.keys():\n",
    "    path = optimize(algos[key][0],algos[key][1],algos[key][2],50000,400).T\n",
    "    paths.append(path)\n",
    "    zpaths.append(f(*path))\n",
    "    methods.append(key)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.contour(x, y, z, levels=np.logspace(0, 5, 35), norm=LogNorm(), cmap=plt.cm.jet)\n",
    "ax.plot(*minima, 'r*', markersize=10)\n",
    "\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "\n",
    "ax.set_xlim((xmin, xmax))\n",
    "ax.set_ylim((ymin, ymax))\n",
    "\n",
    "anim = TrajectoryAnimation(*paths, labels=methods, ax=ax)\n",
    "\n",
    "ax.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = plt.axes(projection='3d', elev=50, azim=-50)\n",
    "\n",
    "ax.plot_surface(x, y, z, norm=LogNorm(), rstride=1, cstride=1, edgecolor='none', alpha=.8, cmap=plt.cm.jet)\n",
    "ax.plot(*minima, f(*minima), 'r*', markersize=10)\n",
    "\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "ax.set_zlabel('$z$')\n",
    "\n",
    "ax.set_xlim((xmin, xmax))\n",
    "ax.set_ylim((ymin, ymax))\n",
    "\n",
    "anim = TrajectoryAnimation3D(*paths, zpaths=zpaths, labels=methods, ax=ax)\n",
    "\n",
    "ax.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${\\displaystyle f(x,y)=\\sin ^{2}3\\pi x+\\left(x-1\\right)^{2}\\left(1+\\sin ^{2}3\\pi y\\right)}\n",
    "{\\displaystyle +\\left(y-1\\right)^{2}\\left(1+\\sin ^{2}2\\pi y\\right)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rosenbrock Function\n",
    "\n",
    "pi = np.pi\n",
    "# LÃ©vi function \n",
    "# f  = lambda x, y: (np.sin(3*pi*x))**2 + ((x-1)**2)*(1+np.sin(3*pi*y)**2)+((y-1)**2)*(1+np.sin(2*pi*y)**2)\n",
    "f = lambda x,y: (1-x)**2 + 100*(y-x**2)**2\n",
    "def f_var(var):\n",
    "    x = var[0]\n",
    "    y = var[1]\n",
    "    return (1-x).pow(2) + 100*(y-x.pow(2)).pow(2)\n",
    "#     return (3*pi*x).sin().pow(2) + ((x-1).pow(2))*(1+(3*pi*y).sin().pow(2))+((y-1).pow(2))*(1+(2*pi*y).sin().pow(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, xmax, xstep = -10, 10, .4\n",
    "ymin, ymax, ystep = -10, 10, .4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.meshgrid(np.arange(xmin, xmax + xstep, xstep), np.arange(ymin, ymax + ystep, ystep))\n",
    "z = f(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minima = getMinima(1,1)\n",
    "f(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rand = lambda : np.add(np.random.rand(1,2)*16,-8*np.ones((1,2)))[0]\n",
    "rand = lambda : np.array([-4., 3.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amsgrad import Amsgrad\n",
    "\n",
    "# x0 = np.array([-3., 4.])\n",
    "x0 = np.array([-4., 3.])\n",
    "\n",
    "algos = {}\n",
    "\n",
    "w_amsgrad = Variable(torch.FloatTensor(rand()), requires_grad=True)\n",
    "amsgrad = Amsgrad([w_amsgrad])\n",
    "algos['amsgrad'] = [amsgrad,f_var,w_amsgrad]\n",
    "\n",
    "w_adam = Variable(torch.FloatTensor(rand()), requires_grad=True)\n",
    "adam = torch.optim.Adam([w_adam], lr=0.01)\n",
    "algos['adam'] = [adam,f_var,w_adam]\n",
    "\n",
    "w_adadelta = Variable(torch.FloatTensor(rand()), requires_grad=True)\n",
    "adadelta = torch.optim.Adadelta([w_adadelta])\n",
    "algos['adadelta'] = [adadelta,f_var,w_adadelta]\n",
    "\n",
    "w_adagrad = Variable(torch.FloatTensor(rand()), requires_grad=True)\n",
    "adagrad = torch.optim.Adagrad([w_adagrad], lr=1)\n",
    "algos['adagrad'] = [adagrad,f_var,w_adagrad]\n",
    "\n",
    "w_rmsprop = Variable(torch.FloatTensor(rand()), requires_grad=True)\n",
    "rmsprop = torch.optim.RMSprop([w_rmsprop])\n",
    "algos['rmsprop'] = [rmsprop,f_var,w_rmsprop]\n",
    "\n",
    "\n",
    "sgd_lr = 1e-9\n",
    "\n",
    "w_sgd = Variable(torch.FloatTensor(rand()), requires_grad=True)\n",
    "sgd = torch.optim.SGD([w_sgd], lr=sgd_lr)\n",
    "algos['sgd'] = [sgd,f_var,w_sgd]\n",
    "\n",
    "w_sgdm = Variable(torch.FloatTensor(rand()), requires_grad=True)\n",
    "sgdm = torch.optim.SGD([w_sgdm], lr=1e-11, momentum=0.9)\n",
    "algos['sgd_momentum'] = [sgdm,f_var,w_sgdm]\n",
    "\n",
    "w_nesterov = Variable(torch.FloatTensor(rand()), requires_grad=True)\n",
    "nesterov = torch.optim.SGD([w_nesterov], lr=sgd_lr, momentum=0.9, nesterov=True)\n",
    "algos['sgd_nesterov'] = [nesterov,f_var,w_nesterov]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "methods = []\n",
    "zpaths = []\n",
    "\n",
    "for key in algos.keys():\n",
    "    path = optimize(algos[key][0],algos[key][1],algos[key][2],50000,100).T\n",
    "    paths.append(path)\n",
    "    zpaths.append(f(*path))\n",
    "    methods.append(key)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.contour(x, y, z, levels=np.logspace(0, 5, 35), norm=LogNorm(), cmap=plt.cm.jet)\n",
    "ax.plot(*minima, 'r*', markersize=10)\n",
    "\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "\n",
    "ax.set_xlim((xmin, xmax))\n",
    "ax.set_ylim((ymin, ymax))\n",
    "\n",
    "anim = TrajectoryAnimation(*paths, labels=methods, ax=ax)\n",
    "\n",
    "ax.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = plt.axes(projection='3d', elev=50, azim=-50)\n",
    "\n",
    "ax.plot_surface(x, y, z, norm=LogNorm(), rstride=1, cstride=1, edgecolor='none', alpha=.8, cmap=plt.cm.jet)\n",
    "ax.plot(*minima, f(*minima), 'r*', markersize=10)\n",
    "\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "ax.set_zlabel('$z$')\n",
    "\n",
    "ax.set_xlim((xmin, xmax))\n",
    "ax.set_ylim((ymin, ymax))\n",
    "\n",
    "anim = TrajectoryAnimation3D(*paths, zpaths=zpaths, labels=methods, ax=ax)\n",
    "\n",
    "ax.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
